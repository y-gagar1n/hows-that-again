{"version":3,"sources":["webpack:///path---blog-video-10-ways-to-get-highload-and-bigdata-2a40a94753b968a20eda.js","webpack:///./.cache/json/blog-video-10-ways-to-get-highload-and-bigdata.json"],"names":["webpackJsonp","486","module","exports","data","markdownRemark","html","frontmatter","path","title","pathContext"],"mappings":"AAAAA,cAAc,gBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,4pMAA6KC,aAAghMC,KAAA,mDAAAC,MAAA,sFAAuJC","file":"path---blog-video-10-ways-to-get-highload-and-bigdata-2a40a94753b968a20eda.js","sourcesContent":["webpackJsonp([13218921337688],{\n\n/***/ 486:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<iframe width=\\\"636\\\" height=\\\"358\\\" src=\\\"https://www.youtube.com/embed/P__hN6u9yCw\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\\n<h1>10 способов достижения HighLoad'а и BigData на ровном месте</h1>\\n<h2>1. Масштабирование</h2>\\n<p>Типичный случай: расчитываем на миллион пользователей, поставили 100 инстансов PostgreSQL, шардирование по created_at.</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>любое взаимодействие, затрагивающее пользователей, лежащих на разных нодах (например, чат) - боль, логика сильно усложняется</li>\\n<li>оказывается, что пользователи, созданные давно - малоактивны, поэтому 90 машин кластера простаивают, а оставшиеся 10 утилизованы на 100%. Надо было шардить по user_id.</li>\\n<li>при обращении к незанятой машине кэш у нее холодный и запарос выполняется в разы дольше</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>нечего было сразу масштабироваться, нужно было сначала вырасти до ресурсов одной машины, потом посчитать стоимость ее апгрейда и только после этого принимать решение о масштабировании</li>\\n</ul>\\n<h2>2. Бизнес хочет хранить данные за все время</h2>\\n<p>Нужны отчеты за все время, поэтому мы в одну огромную базу сохраняем все данные и никогда не удаляем</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>через несколько лет получаем big data на пустом месте</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>ретроспективные данные можно архивировать</li>\\n<li>не хранить сырые данные, а хранить агрегаты по ним (но это если бизнес согласится, что им не понадобятся новые агрегаты)</li>\\n<li>можно партиционировать и на одном сервере хранить архивные данные, на другом - горячие + агрегаты</li>\\n</ul>\\n<h2>3. EAV упрощает проектирование</h2>\\n<p>EAV (Entity-attribute-value) - это подход, используемый когда у нас есть сущности, у которых есть много атрибутов, но используется лишь малая их часть. Тогда создается таблица <code>Attributes</code> с тремя колонками: </p>\\n<ul>\\n<li>Entity: идентификатор сущности</li>\\n<li>Attribute: название атрибута</li>\\n<li>Value: значение атрибута</li>\\n</ul>\\n<p>Применяется, чтобы упростить проектирование</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>все данные лежат в 3-4 гигантских таблицах, которые все время джойнятся. Типы полей <code>Attribute</code> и <code>Value</code> будут, скорее всего, текстовые, а это значит что эффективность индексирования таких данных будет крайне мала. В результате наши джойны будут очень долгими.</li>\\n<li>через некоторое время EAV гордо переименовывается в ядро и обрастает витринами и представлениями с денормализованными данными в реляционном виде. Работает медленно и плохо. Любое изменение в схеме ведет кучу изменений в этих разрозненных представлениях. Чтобы упростить, приходится выкидывать ядро.</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>не лениться и делать отдельные реляционные таблицы</li>\\n</ul>\\n<h2>4. ORM упрощает разработку</h2>\\n<ul>\\n<li>универсальный способ убить производительность любой базы</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>использовать только в прототипах</li>\\n</ul>\\n<h2>5. Главное зло в PostgreSQL - autovacuum</h2>\\n<p>Постоянно работает и всему мешает, в результате чего его выключают.</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>фрагментированная таблица на 100К строк занимает 100 ГБ</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>не отключать и смотреть <a href=\\\"https://www.slideshare.net/PostgreSQL-Consulting/autovacuum-explained-for-engineers-new-improved-version-pgconfeu-2015-vienna\\\">здесь</a> как с ним жить</li>\\n</ul>\\n<h2>6. JOIN это зло - они медленные</h2>\\n<h3>Последствия:</h3>\\n<p>Чтобы не использовать джойн, в контроллер вытягиваются 2 таблицы из базы, они джойнятся средствами ЯП. Затем, чтобы оптимизировать этот велосипедный джойн, добавляется выбор алгоритма - nested loop, hash или merge. В результате получается самодельная БД, только плохая.</p>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>Надо было джойнить и не выпендриваться. Джойны на самом деле быстрые, реляционная база данных оптимизирована для работы с джойнами. </li>\\n</ul>\\n<h2>7. Давайте изобретем Slony</h2>\\n<p>(Slony - система репликации, используемая в PostgreSQL)</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>велосипед всегда работает как-то не так, потому что репликация - это обработка распределенных транзакций, а это тяжело</li>\\n<li>велосипед скорее всего будет работать на уровне SQL, таблиц, триггеров и хранимых процедур. Это медленно и чревато конфликтами.</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>использовать готовые проверенные решения. Если в них чего-то нет, значит тому есть причина. Возможно желаемый функционал просто невозможно реализовать с учетом всех сложностей репликации.</li>\\n<li>в готовых решениях используется репликация лога транзакций на низком уровне</li>\\n</ul>\\n<h2>8. У меня в тесте все работает</h2>\\n<p>Разработчики используют EXPLAIN, но только на своей разработческой машине. А на продакшне данных в 1000 раз больше и все сразу тормозит.</p>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>у разработчиков должен быть какой-то ограниченный доступ к продакшну. В идеале на чтение. Если нельзя, то, например, доступ к мониторингу базы, чтобы после деплоя видеть, сколько ресурсов потребляет каждый запрос. Либо же должны быть отлаженные процедуры работы с DBA, чтобы можно было попросить их прогнать какой-то запрос.</li>\\n</ul>\\n<h2>9. Be smart, as a java-developer</h2>\\n<p>Разработчик хочет быстрее закачать данные в базу, поэтому делает это в 500 тредов. А на стороне БД есть только 10 воркеров (по числу ядер) и в результате 500 тредов, пытающиеся пролезть в 10 воркеров, начинают драться между собой на стороне приложения.</p>\\n<p>SQL-запрос через ко-рутины питона может быть в 10 раз медленнее, чем без них.</p>\\n<h2>10. Приятные мелочи</h2>\\n<p>Если запрос от веба возвращает миллион строк, то:</p>\\n<ul>\\n<li>он никогда не будет работать достаточно быстро для веба</li>\\n<li>стоит подумать, а зачем он нужен? никто не будет читать миллион строк в браузере</li>\\n</ul>\\n<p>20 счетчиков с count(*) на главной странице:</p>\\n<ul>\\n<li>будут работать медленно</li>\\n<li>точные обытно не нужны</li>\\n<li>в постгресе можно написать процедуру, которая будет запрашивать данные от анализатора статистики планировщика. Они будут быстрые, но приблизительные.</li>\\n</ul>\",\"frontmatter\":{\"path\":\"/blog/video/10-ways-to-get-highload-and-bigdata/\",\"title\":\"10 способов достижения HighLoad'а и BigData на ровном месте/Илья Космодемьянский\"}}},\"pathContext\":{}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---blog-video-10-ways-to-get-highload-and-bigdata-2a40a94753b968a20eda.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<iframe width=\\\"636\\\" height=\\\"358\\\" src=\\\"https://www.youtube.com/embed/P__hN6u9yCw\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\\n<h1>10 способов достижения HighLoad'а и BigData на ровном месте</h1>\\n<h2>1. Масштабирование</h2>\\n<p>Типичный случай: расчитываем на миллион пользователей, поставили 100 инстансов PostgreSQL, шардирование по created_at.</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>любое взаимодействие, затрагивающее пользователей, лежащих на разных нодах (например, чат) - боль, логика сильно усложняется</li>\\n<li>оказывается, что пользователи, созданные давно - малоактивны, поэтому 90 машин кластера простаивают, а оставшиеся 10 утилизованы на 100%. Надо было шардить по user_id.</li>\\n<li>при обращении к незанятой машине кэш у нее холодный и запарос выполняется в разы дольше</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>нечего было сразу масштабироваться, нужно было сначала вырасти до ресурсов одной машины, потом посчитать стоимость ее апгрейда и только после этого принимать решение о масштабировании</li>\\n</ul>\\n<h2>2. Бизнес хочет хранить данные за все время</h2>\\n<p>Нужны отчеты за все время, поэтому мы в одну огромную базу сохраняем все данные и никогда не удаляем</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>через несколько лет получаем big data на пустом месте</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>ретроспективные данные можно архивировать</li>\\n<li>не хранить сырые данные, а хранить агрегаты по ним (но это если бизнес согласится, что им не понадобятся новые агрегаты)</li>\\n<li>можно партиционировать и на одном сервере хранить архивные данные, на другом - горячие + агрегаты</li>\\n</ul>\\n<h2>3. EAV упрощает проектирование</h2>\\n<p>EAV (Entity-attribute-value) - это подход, используемый когда у нас есть сущности, у которых есть много атрибутов, но используется лишь малая их часть. Тогда создается таблица <code>Attributes</code> с тремя колонками: </p>\\n<ul>\\n<li>Entity: идентификатор сущности</li>\\n<li>Attribute: название атрибута</li>\\n<li>Value: значение атрибута</li>\\n</ul>\\n<p>Применяется, чтобы упростить проектирование</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>все данные лежат в 3-4 гигантских таблицах, которые все время джойнятся. Типы полей <code>Attribute</code> и <code>Value</code> будут, скорее всего, текстовые, а это значит что эффективность индексирования таких данных будет крайне мала. В результате наши джойны будут очень долгими.</li>\\n<li>через некоторое время EAV гордо переименовывается в ядро и обрастает витринами и представлениями с денормализованными данными в реляционном виде. Работает медленно и плохо. Любое изменение в схеме ведет кучу изменений в этих разрозненных представлениях. Чтобы упростить, приходится выкидывать ядро.</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>не лениться и делать отдельные реляционные таблицы</li>\\n</ul>\\n<h2>4. ORM упрощает разработку</h2>\\n<ul>\\n<li>универсальный способ убить производительность любой базы</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>использовать только в прототипах</li>\\n</ul>\\n<h2>5. Главное зло в PostgreSQL - autovacuum</h2>\\n<p>Постоянно работает и всему мешает, в результате чего его выключают.</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>фрагментированная таблица на 100К строк занимает 100 ГБ</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>не отключать и смотреть <a href=\\\"https://www.slideshare.net/PostgreSQL-Consulting/autovacuum-explained-for-engineers-new-improved-version-pgconfeu-2015-vienna\\\">здесь</a> как с ним жить</li>\\n</ul>\\n<h2>6. JOIN это зло - они медленные</h2>\\n<h3>Последствия:</h3>\\n<p>Чтобы не использовать джойн, в контроллер вытягиваются 2 таблицы из базы, они джойнятся средствами ЯП. Затем, чтобы оптимизировать этот велосипедный джойн, добавляется выбор алгоритма - nested loop, hash или merge. В результате получается самодельная БД, только плохая.</p>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>Надо было джойнить и не выпендриваться. Джойны на самом деле быстрые, реляционная база данных оптимизирована для работы с джойнами. </li>\\n</ul>\\n<h2>7. Давайте изобретем Slony</h2>\\n<p>(Slony - система репликации, используемая в PostgreSQL)</p>\\n<h3>Последствия:</h3>\\n<ul>\\n<li>велосипед всегда работает как-то не так, потому что репликация - это обработка распределенных транзакций, а это тяжело</li>\\n<li>велосипед скорее всего будет работать на уровне SQL, таблиц, триггеров и хранимых процедур. Это медленно и чревато конфликтами.</li>\\n</ul>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>использовать готовые проверенные решения. Если в них чего-то нет, значит тому есть причина. Возможно желаемый функционал просто невозможно реализовать с учетом всех сложностей репликации.</li>\\n<li>в готовых решениях используется репликация лога транзакций на низком уровне</li>\\n</ul>\\n<h2>8. У меня в тесте все работает</h2>\\n<p>Разработчики используют EXPLAIN, но только на своей разработческой машине. А на продакшне данных в 1000 раз больше и все сразу тормозит.</p>\\n<h3>Как надо было:</h3>\\n<ul>\\n<li>у разработчиков должен быть какой-то ограниченный доступ к продакшну. В идеале на чтение. Если нельзя, то, например, доступ к мониторингу базы, чтобы после деплоя видеть, сколько ресурсов потребляет каждый запрос. Либо же должны быть отлаженные процедуры работы с DBA, чтобы можно было попросить их прогнать какой-то запрос.</li>\\n</ul>\\n<h2>9. Be smart, as a java-developer</h2>\\n<p>Разработчик хочет быстрее закачать данные в базу, поэтому делает это в 500 тредов. А на стороне БД есть только 10 воркеров (по числу ядер) и в результате 500 тредов, пытающиеся пролезть в 10 воркеров, начинают драться между собой на стороне приложения.</p>\\n<p>SQL-запрос через ко-рутины питона может быть в 10 раз медленнее, чем без них.</p>\\n<h2>10. Приятные мелочи</h2>\\n<p>Если запрос от веба возвращает миллион строк, то:</p>\\n<ul>\\n<li>он никогда не будет работать достаточно быстро для веба</li>\\n<li>стоит подумать, а зачем он нужен? никто не будет читать миллион строк в браузере</li>\\n</ul>\\n<p>20 счетчиков с count(*) на главной странице:</p>\\n<ul>\\n<li>будут работать медленно</li>\\n<li>точные обытно не нужны</li>\\n<li>в постгресе можно написать процедуру, которая будет запрашивать данные от анализатора статистики планировщика. Они будут быстрые, но приблизительные.</li>\\n</ul>\",\"frontmatter\":{\"path\":\"/blog/video/10-ways-to-get-highload-and-bigdata/\",\"title\":\"10 способов достижения HighLoad'а и BigData на ровном месте/Илья Космодемьянский\"}}},\"pathContext\":{}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/blog-video-10-ways-to-get-highload-and-bigdata.json\n// module id = 486\n// module chunks = 13218921337688"],"sourceRoot":""}