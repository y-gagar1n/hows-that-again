{"version":3,"sources":["webpack:///path---blog-docker-compose-4a43b0829173eab4e471.js","webpack:///./.cache/json/blog-docker-compose.json"],"names":["webpackJsonp","429","module","exports","data","markdownRemark","html","frontmatter","path","title","pathContext"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,0+JAA26GC,aAA+lDC,KAAA,uBAAAC,MAAA,oBAAyDC","file":"path---blog-docker-compose-4a43b0829173eab4e471.js","sourcesContent":["webpackJsonp([267150169503670],{\n\n/***/ 429:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<h1>Docker Compose</h1>\\n<p><a href=\\\"https://docs.docker.com/compose/gettingstarted/\\\">https://docs.docker.com/compose/gettingstarted/</a></p>\\n<p><a href=\\\"https://docs.docker.com/compose/compose-file/\\\">https://docs.docker.com/compose/compose-file/</a></p>\\n<p>Позволяет управлять приложениями, которые используют функциональность нескольких контайнеров сразу.</p>\\n<h2>Создаем YAML-файл</h2>\\n<p><strong>C:/tutorial/docker-compose.yml</strong> </p>\\n<pre><code>version: '2'\\n\\nservices:\\ntarantool:\\ncontainer_name: mytarantool\\nimage: tarantool/tarantool:1.7\\ncommand: tarantool /usr/local/share/tarantool/app.init.lua\\nports:\\n  - 3301:3301\\nvolumes:\\n  - c:/tarantool/app:/usr/local/share/tarantool\\n  - c:/tarantool/data:/var/lib/tarantool\\n</code></pre>\\n<p>Если не указан <code>container_name</code>, то будет использоваться одноименный с сервисом, т.е. в этом случае - tarantool.</p>\\n<p>Если в сервисе указать <code>build: .</code> - это означает искать Dockerfile в той же директории, что и compose-файл. Тогда он попытается сбилдится. (При установке kafka было такое, что из-за windows почему-то не мог сбилдиться докерфайл, пришлось заменить build на Image и использовать готовый)</p>\\n<p><strong>ports</strong> - маппинг портов. Первый идет порт хоста, второй - порт контейнера.</p>\\n<p><strong>volumes</strong> - маунт директорий хоста на директории контейнера. Сначала директория хоста, потом - контейнера.</p>\\n<p><strong>environment</strong> - переменные среды</p>\\n<h2>Создание и запуск контейнера</h2>\\n<p><code>docker-compose -f C:/tutorial/docker-compose.yml up -d</code></p>\\n<p>При этом будут остановлены входящие контейнеры, а потом созданы и запущены заново.</p>\\n<p><strong>-f</strong> - путь к compose-файлу </p>\\n<p><strong>up</strong> - команда \\\"создать и стартовать контейнер\\\"</p>\\n<p><strong>-d</strong> - аналогично detach в docker, стартовать в фоне</p>\\n<p>После этого желательно проверить запущенные контейнеры: <code>docker-compose ps</code></p>\\n<p>Если какой-то из контейнеров не запустился, то можно попробовать поднять еще раз, но без -d, и искать ошибки в логах: <code>docker-compose up</code></p>\\n<p>Можно поднять только некоторые сервисы: <code>docker-compose up service1</code></p>\\n<p>При этом зависимости будут подняты автоматически.</p>\\n<p>Чтобы зависимости не останавливались, не перестраивались и не поднимались, можно указать флаг <strong>--no-dep</strong></p>\\n<h2>Остановка и удаление</h2>\\n<p><code>docker-compose -f C:/tarantool/docker-compose.yml down</code></p>\\n<p>Чтобы удалить все волюмы, созданные этим компоузом на диске хоста, нужно указать флаг <code>--v</code>:</p>\\n<p><code>docker-compose down --v</code></p>\\n<h2>Логи</h2>\\n<p><code>docker-compose logs service1 service2</code> - выдаст аггрегированный лог с этих двух сервисов</p>\\n<h2>Построение образов</h2>\\n<p><code>docker-compose build</code></p>\\n<h2>Скачивание образов</h2>\\n<p><code>docker-compose pull</code></p>\\n<h2>Масштабирование</h2>\\n<p><code>docker-compose up --scale service1=5</code> - запустит 4 дополнительных контейнера</p>\\n<h2>Рестарт контейнера</h2>\\n<p><code>docker-compose -f C:/tarantool/docker-compose.yml restart</code></p>\\n<h2>Остановка сервиса</h2>\\n<p><code>docker-compose stop kafka</code> - остановятся все контейнеры, принадлежащие службе kafka</p>\\n<p>То есть если мы запускали с параметром <code>--scale kafka=5</code>, то остановятся все 5.</p>\\n<p>Если нужно остановить какой-то один, то можем сделать <code>docker stop &#x3C;id контейнера></code>, а <strong>id</strong> посмотреть через <code>docker ps</code></p>\\n<p>А вот как завести какой-то один - не понятно, можно конечно через <code>docker run</code>, но если в <strong>docker-compose.yml</strong> прописаны какие-то специальные параметры запуска, и мы их не укажем, то может и не стартануть. </p>\\n<p>Поэтому на данный момент известен только один выход: <code>docker start kafka</code> - все остановленные контейнеры службы <strong>kafka</strong> перезапустятся.</p>\\n<h2>Пример compose-файла для Kafka с 3 брокерами</h2>\\n<pre><code>version: '2' \\nservices: \\n    zookeeper: \\n        image: wurstmeister/zookeeper \\n        ports: \\n            - \\\"2181:2181\\\" \\n    kafka0: \\n        image: wurstmeister/kafka \\n        ports: \\n            - \\\"9092:9092\\\"\\n        environment: \\n            KAFKA_ADVERTISED_HOST_NAME: 192.168.1.65\\n            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\\n        volumes:\\n            - /var/run/docker.sock:/var/run/docker.sock\\n    kafka1: \\n        image: wurstmeister/kafka \\n        ports: \\n            - \\\"9093:9092\\\"\\n        environment: \\n            KAFKA_ADVERTISED_HOST_NAME: 192.168.1.65\\n            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\\n        volumes:\\n            - /var/run/docker.sock:/var/run/docker.sock\\n    kafka2: \\n        image: wurstmeister/kafka \\n        ports: \\n            - \\\"9094:9092\\\"\\n        environment: \\n            KAFKA_ADVERTISED_HOST_NAME: 192.168.1.65\\n            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\\n        volumes:\\n            - /var/run/docker.sock:/var/run/docker.sock\\n</code></pre>\",\"frontmatter\":{\"path\":\"/blog/docker-compose\",\"title\":\"Docker Compose\"}}},\"pathContext\":{}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---blog-docker-compose-4a43b0829173eab4e471.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<h1>Docker Compose</h1>\\n<p><a href=\\\"https://docs.docker.com/compose/gettingstarted/\\\">https://docs.docker.com/compose/gettingstarted/</a></p>\\n<p><a href=\\\"https://docs.docker.com/compose/compose-file/\\\">https://docs.docker.com/compose/compose-file/</a></p>\\n<p>Позволяет управлять приложениями, которые используют функциональность нескольких контайнеров сразу.</p>\\n<h2>Создаем YAML-файл</h2>\\n<p><strong>C:/tutorial/docker-compose.yml</strong> </p>\\n<pre><code>version: '2'\\n\\nservices:\\ntarantool:\\ncontainer_name: mytarantool\\nimage: tarantool/tarantool:1.7\\ncommand: tarantool /usr/local/share/tarantool/app.init.lua\\nports:\\n  - 3301:3301\\nvolumes:\\n  - c:/tarantool/app:/usr/local/share/tarantool\\n  - c:/tarantool/data:/var/lib/tarantool\\n</code></pre>\\n<p>Если не указан <code>container_name</code>, то будет использоваться одноименный с сервисом, т.е. в этом случае - tarantool.</p>\\n<p>Если в сервисе указать <code>build: .</code> - это означает искать Dockerfile в той же директории, что и compose-файл. Тогда он попытается сбилдится. (При установке kafka было такое, что из-за windows почему-то не мог сбилдиться докерфайл, пришлось заменить build на Image и использовать готовый)</p>\\n<p><strong>ports</strong> - маппинг портов. Первый идет порт хоста, второй - порт контейнера.</p>\\n<p><strong>volumes</strong> - маунт директорий хоста на директории контейнера. Сначала директория хоста, потом - контейнера.</p>\\n<p><strong>environment</strong> - переменные среды</p>\\n<h2>Создание и запуск контейнера</h2>\\n<p><code>docker-compose -f C:/tutorial/docker-compose.yml up -d</code></p>\\n<p>При этом будут остановлены входящие контейнеры, а потом созданы и запущены заново.</p>\\n<p><strong>-f</strong> - путь к compose-файлу </p>\\n<p><strong>up</strong> - команда \\\"создать и стартовать контейнер\\\"</p>\\n<p><strong>-d</strong> - аналогично detach в docker, стартовать в фоне</p>\\n<p>После этого желательно проверить запущенные контейнеры: <code>docker-compose ps</code></p>\\n<p>Если какой-то из контейнеров не запустился, то можно попробовать поднять еще раз, но без -d, и искать ошибки в логах: <code>docker-compose up</code></p>\\n<p>Можно поднять только некоторые сервисы: <code>docker-compose up service1</code></p>\\n<p>При этом зависимости будут подняты автоматически.</p>\\n<p>Чтобы зависимости не останавливались, не перестраивались и не поднимались, можно указать флаг <strong>--no-dep</strong></p>\\n<h2>Остановка и удаление</h2>\\n<p><code>docker-compose -f C:/tarantool/docker-compose.yml down</code></p>\\n<p>Чтобы удалить все волюмы, созданные этим компоузом на диске хоста, нужно указать флаг <code>--v</code>:</p>\\n<p><code>docker-compose down --v</code></p>\\n<h2>Логи</h2>\\n<p><code>docker-compose logs service1 service2</code> - выдаст аггрегированный лог с этих двух сервисов</p>\\n<h2>Построение образов</h2>\\n<p><code>docker-compose build</code></p>\\n<h2>Скачивание образов</h2>\\n<p><code>docker-compose pull</code></p>\\n<h2>Масштабирование</h2>\\n<p><code>docker-compose up --scale service1=5</code> - запустит 4 дополнительных контейнера</p>\\n<h2>Рестарт контейнера</h2>\\n<p><code>docker-compose -f C:/tarantool/docker-compose.yml restart</code></p>\\n<h2>Остановка сервиса</h2>\\n<p><code>docker-compose stop kafka</code> - остановятся все контейнеры, принадлежащие службе kafka</p>\\n<p>То есть если мы запускали с параметром <code>--scale kafka=5</code>, то остановятся все 5.</p>\\n<p>Если нужно остановить какой-то один, то можем сделать <code>docker stop &#x3C;id контейнера></code>, а <strong>id</strong> посмотреть через <code>docker ps</code></p>\\n<p>А вот как завести какой-то один - не понятно, можно конечно через <code>docker run</code>, но если в <strong>docker-compose.yml</strong> прописаны какие-то специальные параметры запуска, и мы их не укажем, то может и не стартануть. </p>\\n<p>Поэтому на данный момент известен только один выход: <code>docker start kafka</code> - все остановленные контейнеры службы <strong>kafka</strong> перезапустятся.</p>\\n<h2>Пример compose-файла для Kafka с 3 брокерами</h2>\\n<pre><code>version: '2' \\nservices: \\n    zookeeper: \\n        image: wurstmeister/zookeeper \\n        ports: \\n            - \\\"2181:2181\\\" \\n    kafka0: \\n        image: wurstmeister/kafka \\n        ports: \\n            - \\\"9092:9092\\\"\\n        environment: \\n            KAFKA_ADVERTISED_HOST_NAME: 192.168.1.65\\n            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\\n        volumes:\\n            - /var/run/docker.sock:/var/run/docker.sock\\n    kafka1: \\n        image: wurstmeister/kafka \\n        ports: \\n            - \\\"9093:9092\\\"\\n        environment: \\n            KAFKA_ADVERTISED_HOST_NAME: 192.168.1.65\\n            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\\n        volumes:\\n            - /var/run/docker.sock:/var/run/docker.sock\\n    kafka2: \\n        image: wurstmeister/kafka \\n        ports: \\n            - \\\"9094:9092\\\"\\n        environment: \\n            KAFKA_ADVERTISED_HOST_NAME: 192.168.1.65\\n            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\\n        volumes:\\n            - /var/run/docker.sock:/var/run/docker.sock\\n</code></pre>\",\"frontmatter\":{\"path\":\"/blog/docker-compose\",\"title\":\"Docker Compose\"}}},\"pathContext\":{}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/blog-docker-compose.json\n// module id = 429\n// module chunks = 267150169503670"],"sourceRoot":""}